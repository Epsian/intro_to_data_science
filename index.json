[{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/r_rstudio/","title":"R and R Studio","tags":[],"description":"","content":" Overview Common Settings Overview R is a programming language and computing environment specialized for statistical analysis and data manipulation. It\u0026rsquo;s commonly used for performing statistical tests, creating data visualizations, and writing data analysis reports. Despite focusing on statistics, it\u0026rsquo;s a full-fledged programming language, and relatively easy to learn.\nYou should have gotten R and R studio install on the first data of SDS 100. If you did not, please follow the guide here.\nCommon Settings There are a few settings I recommend changing in R studio to make the process of working with it a little easier. In the top bar, click on Tools \u0026gt; Global Options and modify the following.\nUnder General \u0026gt; Basic \u0026gt; Workspace, disable \u0026ldquo;Restore .RData into workspace at startup.\u0026rdquo; Under General \u0026gt; Basic \u0026gt; Workspace, set \u0026ldquo;Save workspace to .RData on exit\u0026rdquo; to Never. Under Code \u0026gt; Editing, enable \u0026ldquo;Soft-wrap R source files.\u0026rdquo; Under Code \u0026gt; Display, enable \u0026ldquo;Show Margin\u0026rdquo; with \u0026ldquo;Margin Column\u0026rdquo; set to 80. Under Code \u0026gt; Display, enable \u0026ldquo;Highlight R Function Calls.\u0026rdquo; Under Code \u0026gt; Display, enable \u0026ldquo;Rainbow Parenthesis.\u0026rdquo; Under R Markdown \u0026gt; Basic, disable \u0026ldquo;Show output inline for all R Markdown documents.\u0026rdquo; Under R Markdown \u0026gt; Visual, disable \u0026ldquo;Use visual editor by default for new documents.\u0026rdquo; Under Appearance, pick a theme you like! [WIN ONLY] Under Terminal \u0026gt; General, set \u0026ldquo;New terminals open with\u0026rdquo; to \u0026ldquo;Bash\u0026rdquo; (You can only do this after you complete the install guide 7: Windows Subsystem for Linux) "},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/syllabus/","title":"Syllabus","tags":[],"description":"","content":" Course Description Course Structure Course Instructor Contacting Me Course Policies Required Materials Attendance Academic Honesty Code of Conduct Accommodation Grading Standards-Based Grading Standards Final Grades Late Work Policy FAQ Course Description Introduction to Data Science (SDS 192) aims to equip students with the knowledge and tools to understand, critically evaluate, manipulate, and explain data. This is an introductory course, and no prior experience is necessary1. Students will learn how to read and write code, but also how to create, organize, and collaborate on coding projects while critically examining the projects goals and data sources. We will be primarily using the R language, along with supplemental tools.\nCourse Structure Each week follows the same basic structure. Monday and Wednesday classes include lectures to introduce new concepts. Each lecture is followed by interactive problem sets designed to reinforce concepts through active learning. Slides from lecture will be posted online after class. The problem sets for any class are \u0026ldquo;due\u0026rdquo; at the start of the next class period when the answers will be released; most problem sets can be completed in class. In-class problem sets do not contribute toward your grade. They are intended to reinforce material and help you test your own understanding.\nFriday classes are devoted to lab activities or project work time. Students are expected to come to class for these activities. Labs include more involved problem sets that incorporate topics from the current and prior weeks. Students work on labs in groups of two to four people. Labs are reviewed through GitHub Classroom where feedback is provided.\nFor a full list of assignments and due dates, please see the course schedule.\nThis is a 4-credit course. You should be spending 12-hours total per week on this course. Expect to spend around 8.25 hours (12 hours - 3.75 hours/week of in-class instruction) on class material per week outside of class.\nCourse Instructor I am a sociologist that studies abuses of power in government. I earned my Ph.D.Â at the University of California, Davis in in sociology with a designated emphasis in computational social science. I combine computational methods such as social network analysis, natural language processing, geospatial analysis, and machine learning with open source and governmental data to uncover patterns of malfeasance and misfeasance by our public servants. From the political networks of politicians and prohibition gangsters to bias hidden in the text of academic recruitment, I use new methods to work on old problems of corruption and inequality.\nI am a visiting assistant professor in the Statistical \u0026amp; Data Sciences (SDS) program. I have experience working with both United States and United Kingdom governmental organizations applying machine learning to real-world problems. In the UK, I worked with the national lab for data science and machine learning, the Alan Turing Institute, on early-detection systems in foster care to assure children are receiving adequate services. Meanwhile in the US I worked with the Internal Revenue Service to build a machine learning system that determined the credibility of incoming fraud reports.\nContacting Me Slack Office Hours You can send me a message on the course Slack workspace, and I will respond when I am able, typically within 24 hours during the work week. To message me, click the + button next to \u0026ldquo;Direct Messages\u0026rdquo; and search for my name.\nIf your question is not sensitive in nature, consider putting it in the #coding-help or #course-help channel instead. There is a good chance one of your classmates will be able to answer before I can.\nSlack questions should be brief or administrative in nature. For more in-depth questions and troubleshooting please attend office hours.\nYou can schedule a meeting with me on Calendly. Drop-ins are welcome, but priority is given to those who make an appointment. Group appointments, to address a similar question, are welcome.\nIf you are coming to office hours with a coding question, make sure you have the code ready at the start of your appointment. Have your computer booted up and your project open.\nIf you cannot find an open time slot, please message me for an appointment. I will attempt to find a time that works for both of us.\nCourse Policies Required Materials Students are not expected to buy any materials for this course. Data science is built on free and open collaboration. There is no shortage of high-quality learning material available. This reader, as well as all assignments, are currently available for free.\nStudents are required to have a working computer (preferably a laptop) and reliable internet connection for this course. Any recent computer should be sufficient, with the notable exception of Chromebooks. Chromebooks lack access to the majority of the tools used by data scientists.\nIf you only have access to a Chromebook, please speak with me as soon as possible.\nAttendance I will not be taking attendance in this course, and you do not need to inform me when you will be absent. If you are sick, please stay home. Given the standards-based grading system (discussed below), no single class, assignment, or even quiz will negatively impact your grade. That said, it will be very difficult to keep up with course material without consistent attendance.\nIf you miss a class, you should contact a peer to discuss what was missed, and check the course reader website for any upcoming deadlines. I won\u0026rsquo;t have the capacity to re-deliver missed material in office hours.\nQuizzes cannot be made up after the open period has passed. If you have a known scheduling conflict with a quiz, please speak with me as soon as possible to arrange an alternative time.\nPlease see the SDS department\u0026rsquo;s official policy regarding remote learning:\nIn keeping with Smith\u0026rsquo;s core identity and mission as an in-person, residential college, the Program in Statistical \u0026amp; Data Sciences affirms College policy (as articulated by Provost Michael Thurston and Dean of the College Alex Keller) that students will attend class in person. As such, SDS courses will not provide options for remote attendance. Students who have been determined to require a remote attendance accommodation by the Office of Disability Services will be the only exceptions to this policy. As with any other kind of accommodations under the Americans with Disabilities Act (ADA), please notify your instructor during the first week of classes to schedule a meeting with them to discuss how we can work with you to provide the most accessible course possible.\nAcademic Honesty Data science is inherently collaborative, so I fully expect students to collaborate. You are encouraged to work together on most assignments\u0026mdash;ask questions on Slack, create study groups, and share helpful resources you find. However, anything you submit must be your own work. You need to be the person who writes the text and/or code. Multiple students should not submit identical work. Please note: The only avenue in which collaboration is not allowed is on quizzes.\nAll students, staff, and faculty are bound by the Smith College Honor Code:\nStudents and faculty at Smith are part of an academic community defined by its commitment to scholarship, which depends on scrupulous and attentive acknowledgement of all sources of information and honest and respectful use of college resources.\nSmith College expects all students to be honest and committed to the principles of academic and intellectual integrity in their preparation and submission of course work and examinations. All submitted work of any kind must be the original work of the student who must cite all the sources used in its preparation.\n-Smith Academic Honor Code Any cases of dishonesty or plagiarism will be reported to the Academic Honor Board. Examples of dishonesty or plagiarism include:\nSubmitting work completed by another student as your own. Copying and pasting text or code from sources without quoting and citing the author. Paraphrasing material from another source without citing the author. Failing to cite your sources correctly. Falsifying or misrepresenting information in submitted work. Paying another student or service to complete assignments for you. Learning to code is similar to learning a new language; you will only learn by doing. No amount of rote copying will advance you beyond the most elementary levels of understanding. Please keep this in mind.\nIf someone else helps you understand a concept better, give them a nod in the #shoutouts channel on Slack.\nCode of Conduct As participants in this course we are committed to making participation a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor I have the right and responsibility to point out and stop behavior that is not aligned with this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\nAll students and the instructor are expected to adhere to this Code of Conduct in all settings for this course: seminars, office hours, and over Slack.\nThis Code of Conduct is adapted from the Contributor Covenant.\nAccommodation Smith College is committed to providing support services and reasonable accommodations to all students with disabilities. To request an accommodation, please register with the Office of Disability Services Office (ODS) at the beginning of the semester.\nGrading Standards-Based Grading This course will be graded using a standards-based grading system. Rather than tallying up the percentage of questions you answer correctly, I assess your responses by using a pre-defined set of course standards and then assign a level of proficiency. Throughout the semester, this course offers multiple opportunities to showcase the depth of your understanding in light of these standards.\nIn traditional points-style grading, an average is taken of all your assignments, and your final grade is based on that average. This means all assignments are given equal consideration in your final grade.\nMean of\nA1-A5 In contrast, standards-based grading is focused on your progression through the course. Functionally, only your best score for each standard is kept. All others are effectively forgotten. The hope is that without the worry of \u0026ldquo;getting a bad grade\u0026rdquo; when you are new to a concept, you will feel free to safely engage with complicated topics early on, make mistakes, and have opportunities to show improvement without penalization.\nMax of\nA1-A5 A standards-based grading system carries a number of other benefits:\nLearning targets for the course are clearly defined from the outset. Every graded assignment is directly tied to at least one standard. There is no \u0026ldquo;busy work\u0026rdquo; with a standards-based system. No single assignment will make-or-break your grade. You have multiple opportunities to demonstrate fluency in a standard. This rewards students that take the time to practice and learn from their mistakes. It prioritizes student growth throughout the course of the semester. Assessments in a standards-based system are much clearer than in a point-based grading system. Saying that I\u0026rsquo;ve become proficient in data wrangling, joining, and visualizing means more than saying that I earned a 92.5 in my Introduction to Data Science course. A standards-based grading system makes it easier to monitor your own progress towards a certain grade. There is no competition and no curve in a standards-based system. The only person you are ever compared with is your past self. Help each other often and freely. Standards The following table lists all the standards you are evaluated on in this course. There are 15 total standards, separated into 4 categories. Each standard states what conditions must be met to reach each proficiency level. There are four proficiency levels for each standard, each requiring more complete understanding of the material. These levels are inclusive, meaning to reach the 4th level, \u0026ldquo;Exceeds Standard\u0026rdquo; you must also meet all the requirements of level 3, \u0026ldquo;Meets Standard.\u0026rdquo;\nYou will have multiple opportunities to demonstrate your understanding of each standard. Any assignment that is reviewed is an opportunity to increase your proficiency level in a standard. In addition to the four levels of proficiency, there is also an extra point available in each standard called \u0026ldquo;Individual Standard.\u0026rdquo; You may fulfill this requirement only on quizzes, but only need to reach the \u0026ldquo;Meets Standard\u0026rdquo; criteria on a standard to do so.\nYou can demonstrate proficiency in any reviewed assignment, but can only fulfill the \u0026ldquo;Individual Standard\u0026rdquo; criteria on a quiz.\nStandard Does Not Meet Standard Progressing Toward Standard Meets Standard Exceeds Standard Individual Standard Data Importing Cannot import data or uses R Studio visual tools to import data. Manually organizes or modifies data before importing it into R. Can import raw data into R using the appropriate function for the data source. Can interface with APIs or other remote sources and import data directly into R. Data Cleaning Cleans data in a non-programmatic way. Can clean data programmatically on a cell-by-cell basis to prepare it for analysis. Can assign the correct common data types (logical, integer, numeric, factor, and string) to loaded data and understand the uses of each. Can clean data for analysis in a vectorized way. Can prepare data for advanced types (dates, time series, etc.). Can prepare data from non-traditional sources such as OCR or web scraping. Data Reshaping Formats data in a non-programmatic way. Can derive new measures from existing data and append it to dataframes. Can pivot data between wide and long formats, and can explain the use case of each. Can transition data between data frames and lists, and explain the applications of data in a list format. Data Aggregation \u0026amp; Subsetting Transforms data in a non-programmatic way. Creates multiple copies of data in several intermediate stages of transformation that are used for different steps of analysis. Can combine and split data sets using the appropriate merge or subset techniques. Can split or merge data sets using either SQL-like calls or approximate matching. Functions Copies-and-pastes similar code with small changes. Creates simple functions with consistent inputs. Creates simple functions that can handle novel inputs, with logic to handle the data appropriately. Creates complex functions that can handle arbitrary input. Includes built in error checking and warnings. Iteration Copies-and-pastes similar code several times within or between scripts. Uses for loops or apply functions to iterate through vector data to preform a single data manipulation. Can use either loops or apply functions to iterate over a vector of data and preform multi-step manipulations. Can use loops or apply functions and explain the use cases for each. Can iterate over complex data structures such as dataframes or lists. Visualization Structure Selects inappropriate formats for data visualization. Selects sub-optimal visualization formats or uses excessive visualizations where a single one would be sufficient. Selects suitable formats for data visualization (bar, line, boxplot, etc.) and can explain the reasoning behind that choice. Effectively mixes visualization formats or isolates individual elements to clearly communicate a message. Visualization Aesthetics Chooses visual cues and colors for purely aesthetic reasons without attention to data representation. Data visualizations attempt to represent underlying data, but use methods unsuited to the task which leave ambiguity for the viewer. Data visualizations use color, scale, and shapes effectively to differentiate and communicate underlying data. Data visualizations are highly customized with bespoke elements, such as callouts, to clearly communicate the message of the visualization. Aesthetics are sensitive to accessibility concerns. Visualization Context Produces data visualizations that are unclear, confusing, devoid of context, or impossible to understand without reading the text. Produces data visualizations with readable axis labels, units, and legends (where appropriate). Produces data visualizations that are clear and understandable with minimal text captions. Produces data visualizations that are self-contained and can be understood on their own without textual explanation. Data Ethics Does not consider data ethics or investigate data provenance. Can articulate common pitfalls and relate them to the project at hand. Confirms data types and scales using data documentation. Reads data documentation to understand data collection/generation and measurements. Can highlight potential concerns specific to the data or project. Either creates data documentation for used data, or includes notes in code to the data sources and explains potential pitfalls. Considers and articulates relevant concerns related to the current project unprompted throughout the work cycle. Code Style Code style is inconsistent and/or lacks documentation. Code comments explain the broad strokes of intended behavior. Indentation is consistent and predictable. Uses print statements to track the status of code execution. Consistently comments all code with clearly organized sections. Expected inputs and outputs are clearly explained. Uses error messages or print statements within their code to locate the causes of errors and resolve them. Code is clearly commented, with standardized formatting and indentation. Code contains tests which will check for errors, and report those errors if they arise. Git/Github Does not use git for version control. Uses git and GitHub for version control and can contribute to group repositories with commits, pushes, and pulls. Uses git and GitHub effectively. Code commits are of appropriate size and commented well. Can branch and merge repositories while resolving any merge conflicts. Does not include sensitive files in commits. Uses Github effectively for collaboration. Can create issues, ask for review, and merge branches in a manner suitable for a collaborative environment. Final Grades Your completion of these standards are converted into a final letter grade using the following process. Each of the 12 standards will be converted into a four-point scale, with one point available for meeting the \u0026ldquo;Individual Standard\u0026rdquo; on a quiz.\n1 Point. \u0026ldquo;Does Not Meet Standard\u0026rdquo; 2 Points. \u0026ldquo;Progressing Toward Standard\u0026rdquo; 3 Points. \u0026ldquo;Meets Standard\u0026rdquo; 4 Points. \u0026ldquo;Exceeds Standard\u0026rdquo; +1 Point. \u0026ldquo;Individual Standard\u0026rdquo; On this scale, there are 60 points total in the course (12 standards * 5 possible points). I sum the highest level of proficiency you reach in each standard over the course of the semester to arrive at your final score. For example, if someone were to reach \u0026ldquo;Exceeds Standard\u0026rdquo; in all standards, but could never do so on a quiz, they would receive 48 of 60 points (4 points * 12 standards). Similarly, if someone reaches \u0026ldquo;Meets Standard\u0026rdquo; in all topics, including on quizzes, but did not reach \u0026ldquo;Exceeds Standard\u0026rdquo; in any topic, they would likewise receive 48 of 60 points.\nThe summed points will be converted into letter grades using the following table.\nLetter Points A 57-60 A- 54-56 B+ 52-53 B 50-51 B- 48-49 C+ 46-47 C 44-45 C- 42-43 D+ 40-41 D 38-39 D- 36-37 F 0-35 Late Work Policy Assignments turned in late will not be reviewed, and will not be considered for demonstrating proficiency in course standards. Keep in mind, missing an assignment will not hurt your grade, but does remove one chance for you to demonstrate your knowledge of course material. If you do not think you will be able to turn in an assignment by the deadline, you may request an extension. To do so, please send me a message explaining why you are unable to complete the assignment in the expected time frame. Extension requests must be made\u0026ndash;and accepted\u0026ndash;before the assignment due date.\nAfter the due date, late assignments are only reviewed if there are emergency circumstances preventing you from turning the assignment in on time.\nFAQ Q: So if I reach \u0026ldquo;Exceeds Standard\u0026rdquo; and fulfill the individual standard on a quiz for a topic early in the semester, I can just skip those questions for the rest of the class?\nA: Theoretically yes, but I would recommend you answer all questions to make sure you\u0026rsquo;re not letting your knowledge slip.\nIf this is your first course in the SDS department, you also need to enroll in SDS 100.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/git/","title":"git","tags":[],"description":"","content":" Overview git on Windows git on Mac Overview git is a tool for version control and collaboration. It is the tool used by data science teams big and small to keep track of code. Think of it like track changes in Word or Google docs, but for code files.\nYou will also need an account on Github. Please create one here.\ngit on Windows Follow these step-by-step instructions if you\u0026rsquo;re installing Git on a Windows machine:\nFirst, launch a web browser, the image below shows the Microsoft Edge browser.\nNext, navigate to the following Git download URL in your browser https://git-scm/com/downloads.\nSelect \u0026ldquo;Windows\u0026rdquo; from the Downloads portion of the Git webpage. Git will display the following page and automatically being downloading the correct version of the Git software. If the download doesn\u0026rsquo;t start automatically, click on the \u0026ldquo;Click here to download manually link.\u0026rdquo;\nWhen the download is complete, open/Run the downloaded file (it may look different in different browsers).\nA screen will appear asking for permissions for the Git application to make changes to your device. Click on the Yes button.\nClick Next to accept the user license.\nLeave the default \u0026ldquo;Destination Location\u0026rdquo; unchanged (usually C:\\Program Files\\Git) and hit Next\nYou will see a screen like the one below asking you to \u0026ldquo;Select Components.\u0026rdquo; Leave all of the default components selected. You can also check the boxes next to \u0026ldquo;Additional Icons\u0026rdquo; and it\u0026rsquo;s sub-item, \u0026ldquo;On the Desktop\u0026rdquo; if you would like. Your completed configurations window should have the following components selected:\nAdditional Icons -\u0026gt; On the Desktop Windows Explorer integration -\u0026gt; Git Bash Here -\u0026gt; Git GUI Here Git LFS (Large File Support) Associate .git* configuration files with default text editor Associate .sh files to be run with Bash The next screen will ask you to pick a \u0026ldquo;default editor, click the drop down box and select\u0026quot;Use the Nano editor by default.\u0026rdquo; The press Next.\nOn the next screen, it will ask to override the default \u0026ldquo;branch name.\u0026rdquo; Select the \u0026ldquo;Override the default branch name for new repositories\u0026rdquo; option, and in the text box type \u0026ldquo;main.\u0026rdquo; Press Next.\nThe next screen will ask you if you want to adjust your path environment. Leave the default of \u0026ldquo;Git from the command line and also from 3rd-party software.\u0026rdquo; Press Next.\nOn the next screen, keep the default option of \u0026ldquo;Use bundled OpenSSH.\u0026rdquo; Press Next\nOn the next screen, keep the default option of \u0026ldquo;Use the OpenSSL library.\u0026rdquo; Press Next.\nLeave the default \u0026ldquo;Checkout Windows-style, commit Unix-style line endings\u0026rdquo; selected on the next page and hit Next:\nKeep the default \u0026ldquo;Use MinTTY (the default terminal of MSYS2)\u0026rdquo; selected on the \u0026ldquo;Configuring the terminal emulator to use with Git Bash\u0026rdquo; window and hit Next:\nKeep the default value of \u0026ldquo;Default (fast-forward or merge)\u0026rdquo; on the \u0026ldquo;Choose the default behavior of \u0026lsquo;git pull\u0026rsquo;\u0026rdquo; page and hit Next:\nKeep the default value of \u0026ldquo;Git Credential Manager Core\u0026rdquo; on the \u0026ldquo;Choose a credential helper\u0026rdquo; page and hit Next:\nKeep the default values on the \u0026ldquo;Configuration extra options\u0026rdquo; page by keeping \u0026ldquo;Enable file system caching\u0026rdquo; checked and \u0026ldquo;Enable symbolic links\u0026rdquo; unchecked and then hit Next:\nMake sure that no options are checked in the \u0026ldquo;Configuring experimental options\u0026rdquo; page and hit Install:\nAfter you hit this Install button as per above, you will see an install progress screen like the one below:\nWhen the install is complete, a new, \u0026ldquo;Completing the Git Setup Wizard\u0026rdquo; window like the one below will appear:\nMake sure that all of the options on this window are unchecked as in the image below and then hit the Finish button:\nThis will complete your installation process. Type in git --version to check if everything was installed correctly. If you see git version \u0026lt;NUMBERS\u0026gt; you\u0026rsquo;re all set. Now we need to configure some settings. Right click on your desktop, and click on \u0026ldquo;Git Bash here.\u0026rdquo; A black terminal window will open.\nClick on the window, and then copy the following and press enter, changing \u0026ldquo;Jane Doe\u0026rdquo; to your name. You must put your name in quotes. git config --global user.name \u0026quot;Jane Doe\u0026quot;\nLastly, copy the following and press enter, changing the email to your email address. git config --global user.email jdoe@example.com\ngit on Mac To install git on a Mac, first open the launchpad by pressing F4 or by making a pinch motion on the track pad with three fingers and your thumb.\nA terminal window will open up, showing your account name and then a $, with a flashing cursor afterwards. You will enter text here to issue commands.\nEnter type in the word git and press enter.\nA window will pop up, asking if you want to install \u0026ldquo;developer tools.\u0026rdquo; Click Install.\nA prompt will appear asking you to agree to the license agreement, click Agree.\nThe software will then start installing. It will take a few minutes to finish. When it is done you will see the following window. Click Done.\nTo make sure everything is installed correctly, go back to the terminal window and enter git --version. You should see a message that says git version \u0026lt;NUMBERS\u0026gt;. If you do, you can move on.\nNext we will need to set up some options. Fist, copy the following into the terminal and press enter to change the default branch name: git config --global init.defaultBranch main\nNext, copy the following and press enter, changing \u0026ldquo;Jane Doe\u0026rdquo; to your name. You must put your name in quotes. git config --global user.name \u0026quot;Jane Doe\u0026quot;\nLastly, copy the following and press enter, changing the email to your email address. git config --global user.email jdoe@example.com\nThanks to the UC Davis DataLab\u0026rsquo;s Install Guide for providing a portion of this guide.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/","title":"Install Guides","tags":[],"description":"","content":" R and R Studio Overview Common Settings Overview R is a programming language and computing environment specialized for statistical analysis and data manipulation. It\u0026rsquo;s commonly used for performing statistical tests, creating data visualizations, and writing data analysis reports. Despite focusing on statistics, it\u0026rsquo;s a full-fledged programming language, and relatively easy to learn. You should have gotten R and R studio install on the first data of SDS 100. If you did not, please follow the guide here.\ngit Overview git on Windows git on Mac Overview git is a tool for version control and collaboration. It is the tool used by data science teams big and small to keep track of code. Think of it like track changes in Word or Google docs, but for code files. You will also need an account on Github. Please create one here. git on Windows Follow these step-by-step instructions if you\u0026rsquo;re installing Git on a Windows machine:\nGithub Overview Create an Account Creating SSH Keys and Adding to Github Overview Github is a online code repository that great expands the utility of git. It acts as a clearinghouse for code, and is used worldwide by researchers, government, and industry. Create an Account First up, we need to create an account on github.com. Navigate to the site, and click the Sign up button in the upper right. Enter your email and create a password.\nDB rowser Overview DB Browser on Windows DB Browser on Mac Overview DB Browser is an ultra lightweight viewer for SQLite databases. It is made to allow those familiar with spreadsheets to work more easily with the common SQLite format. However, that is all that it does; you cannot use it on other database types. DB Browser on Windows First head to the DB Browser download page, and select the version that matches your system.\nOpenRefine Overview OpenRefine on Windows OpenRefine on Mac Overview OpenRefine is an open source tool used to clean and pre-process messy data. While most people are familiar with data cleaning in their coding tool of choice (R, Python, Julia, etc.), OpenRefine is designed to provide powerful cleaning capabilities with minimal overhead. One of the most helpful capabilities of OpenRefine is the ability to check for possible duplicates and misspellings of text data using it\u0026rsquo;s text facet tools.\nR Packages Overview Overview R uses a number of packages to work with data, which are largely community created. This means many of them do not come pre-installed with R. Here is a list of packages we will use this semester. You should be able to paste this into the R console and press enter to install them all at once. install.packages(\u0026quot;tidyverse\u0026quot;); install.packages(\u0026quot;dplyr\u0026quot;); install.packages(\u0026quot;skimr\u0026quot;); install.packages(\u0026quot;ggplot2\u0026quot;); install.packages(\u0026quot;mosaic\u0026quot;); install.packages(\u0026quot;plotly\u0026quot;); install.packages(\u0026quot;todor\u0026quot;); install.packages(\u0026quot;compareDF\u0026quot;); install.packages(\u0026quot;future\u0026quot;); install.packages(\u0026quot;rvest\u0026quot;); install.\n[WIN ONLY] Windows Subsystem for Linux Overview Check your windows version Windows version larger than (or equal to) 19041 Windows version smaller than 19041 Verifying your install Overview Windows now has the ability to install a linux operating system on your machine without the use of an emulator. This gives you a full-featured linux environment that can interact with your normal files. Check your windows version First, please check the build version of Windows that you are using.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/github/","title":"Github","tags":[],"description":"","content":" Overview Create an Account Creating SSH Keys and Adding to Github Overview Github is a online code repository that great expands the utility of git. It acts as a clearinghouse for code, and is used worldwide by researchers, government, and industry.\nCreate an Account First up, we need to create an account on github.com. Navigate to the site, and click the Sign up button in the upper right.\nEnter your email and create a password.\nYou will most likely receive an email from Github asking to confirm your account. Go and click that.\nCreating SSH Keys and Adding to Github Creating a new SSH key will invalidate all the places your current SSH key is used!\nSSH Keys are a way to identify your computer when accessing external resources. Think about it like a password for your computer to log in by itself. The first thing we need to do is create an SSH key for your computer. Open up R Studio, and click on the Terminal tab in the bottom left pane. Copy the following, enter your correct email, and press enter to create a key: ssh-keygen -t ed25519 -C \u0026quot;your_email@example.com\u0026quot;\nThe terminal will look slightly different in my pictures, but the process is the same in the R Studio terminal.\nIt will ask where you want to save the key. Accept the defaults by pressing Enter.\nIt will then ask you to create a pass phrase, press enter twice to skip this step.\nIt will then show a printout of your key, and a little bit of art. I\u0026rsquo;ve greyed mine out here for security.\nNext, type cd and press enter, followed by cat .ssh/id_ed25519.pub. It will print out a code starting with \u0026ldquo;ssh-ed25519 \u0026hellip; your_email@smith.edu.\u0026rdquo; You want to highlight all of that, including the \u0026ldquo;ssh-ed25519\u0026rdquo; and your email, press CTRL or command + C to copy it.\nWe will now return to github.com and login.\nIn the upper right hand corner you will see your user profile dropdown. Click on that and go to Settings.\nOn your setting screen, in the left hand menu, click on \u0026ldquo;SSH and GPG keys.\u0026rdquo;\nOn the next screen, click the green button in the upper right that says \u0026ldquo;New SSH Key.\u0026rdquo;\nOn the following screen, name your key, and paste the text we copied into the \u0026ldquo;Key\u0026rdquo; box. Then press the \u0026ldquo;Add SSH Key\u0026rdquo; button.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/class_worksheets/","title":"Worksheets","tags":[],"description":"","content":" R/R studio Worksheet Practise some R fundamentals.\ngit Worksheet Practise some git fundamentals.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/dbbrowser/","title":"DB rowser","tags":[],"description":"","content":" Overview DB Browser on Windows DB Browser on Mac Overview DB Browser is an ultra lightweight viewer for SQLite databases. It is made to allow those familiar with spreadsheets to work more easily with the common SQLite format. However, that is all that it does; you cannot use it on other database types.\nDB Browser on Windows First head to the DB Browser download page, and select the version that matches your system. On Windows this is most likely the 64-bit standard installer.\nOnce the download has finished, start the installer from the browser or your download location.\nOnce you have started the installer, press the Next button to continue.\nOn the next screen, accept the license agreement and press Next. The following page will ask you if you would like to place shortcuts anywhere. Desktop will place icons on your desktop, while Program Menu will add options to your right click menu. You can choose to have these if you wish, I will not. Press Next once you have decided.\nOn the following screen, you will be asked to select what components you want to install and where. You can safely keep the defaults and continue. Press Install on the following page.\nOne the installation is complete, you can press Finish to close the installer!\nDB Browser on Mac First head to the DB Browser download page, and select the version that matches your system. There should only be one for Macs.\nOnce the download has finished, launch the installer. You will most likely see an alert from your browser.\nTo finish installing, drag the DB Browser icon into your apps folder.\nThanks to the UC Davis DataLab\u0026rsquo;s Install Guide for providing a portion of this guide.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/labs/","title":"Labs","tags":[],"description":"","content":"All labs will be turned in through Github Classroom. You will set up your student account in the process on completing your first lab. Click the link below to open the lab.\nLab 0: Problem Solving Mini-Lab Lab 1: R Coding "},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/class_worksheets/4_r_rstudio/","title":"R/R studio Worksheet","tags":[],"description":"","content":" Overview Problem Sets 1. Data Types 2. Vectors 3. Objects 4. NAs 5. Dataframes 6. Conditionals Overview Learning to code is like learning a language, meaning you can only get better by practicing. Today we\u0026rsquo;re going to practice some R fundamentals. You are encouraged to work with your neighbors on these problems. If you ever get stuck, call over myself or the data assistant for help.\nProblem Sets 1. Data Types There are five main data types in R, they are:\nlogical - TRUE or FALSE integer - whole numbers like 1, 5, 100 numeric - numbers with decimal places like 5.25 character - anything with letters factors - for categorical data, numbers with descriptive labels NA - NA are the absence of data, or something missing. Depending on the type of data, you can only perform certain actions on them. For example, in the console, type 1 + 4 and press enter. Works fine! Now try 1 + \u0026quot;pie\u0026quot;. No good. In the later example, we tried to add a numeric and a character, which R can\u0026rsquo;t understand.\nFor each of the following, try using the class() function to discover the data type. Try to guess what each one is before you run the function.\n5 6.4 TRUE \u0026quot;FALSE\u0026quot; 2. Vectors Everything in R is a vector, which is an ordered arrangement of data of the same type. Even single bit of data, like if you enter \u0026quot;a\u0026quot; into the console, returns [1] \u0026quot;a\u0026quot;, which is showing a vector of length 1, with our data \u0026quot;a\u0026quot; in it. You can test it out yourself using the length() function.\nIn the console, type length(\u0026quot;a\u0026quot;) and press enter. The length() function will look at a vector, and tell you how many elements it has, or how many pieces of data there are inside it. As an example, try the following; in the console type c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;), it returns a vector with three elements. Now try length(c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;)), what did it return? Notice that is only returned a single number describing the vector it was given.\nYou can also run class() on a vector, which is an ordered arrangement of data. you can make vectors using the c(), or combine, function. Try to guess the type of the following vectors before using class(). Remember, a vector can only hold one type of data!\nc(1, 2, 3, 4) c(\u0026quot;five\u0026quot;, \u0026quot;six\u0026quot;, \u0026quot;seven\u0026quot;) c(8, \u0026quot;9\u0026quot;, 10) c(TRUE, FALSE) Vectors take some getting used to, but as you come to understand how they work, you will be able to take advantage of how powerful R really is. One important property of a vector is that you can apply actions to all elements of a vector at once. For example, once again run 1 + 4 in the console. You will get back a vector of length 1, with the result of [1] 5, meaning the element in position 1 of our vector is 5. Now try 1 + c(4, 5, 6, 7). What do you think will happen?\nThis vectorized mode of thinking takes some time to get used to. Run the following after trying to anticipate the results:\n5 + c(10, 20, 30) c(10, 50, 100) / 5 c(1, 5, 10) + c(2, 4, 8) Really take the time to think over these results, especially the third one.\nExplain the results of 5 + c(10, 20, 30) and c(1, 5, 10) + c(2, 4, 8). What is being done to each vector that would cause the results we are seeing?\nIn the first example (5 + c(10, 20, 30)) five is being added to each element of the vector.\nIn the second example (c(1, 5, 10) + c(2, 4, 8)) each element of the vector is being added with the element in the same position of the other vector.\nSome functionalities of R only make sense on a vector, for example, taking the mean() or average. It would be pointless to take the average of one number!\nTry this:\nmean(c(1, 5, 10))\n3. Objects You don\u0026rsquo;t have to type out your vector every time you want to use it, you can save it to an object using an assignment. Try typing letter_vec \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;) and pressing enter. You should see letter_vec appear in your environment tab on the upper right. Type letter_vec into the console and press enter. We see the same data as if we had just entered c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;) again, because that is what we saved inside the letter_vec object.\nCreate a vector called number_vec of 10 numbers. The numbers can be any you like.\nnumber_vec \u0026lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\nWe can now start to do things to the object we created. Try using class() and length() on our letter_vec and number_vec objects.\nYou can use vectors with each other as well. Try the following: number_vec + number_vec\nYou can ask for only part of a vector by using the square brackets [ ]. Say we wanted the letters in the first, third, and fifth positions of our letter_vec object. I could ask R for letter_vec[c(1, 3)], and get back c(\u0026quot;a\u0026quot;, \u0026quot;c\u0026quot;).\nCreate a vector called example_vector containing c(1, 3, 5, 7, 9, 11), and then get the values in the fourth, fifth, and sixth position.\nexample_vector \u0026lt;- c(1, 3, 5, 7, 9, 11)\nexample_vector[c(4, 5, 6)]\n4. NAs NAs are missing values. They cause a lot of problems, and are very common. A good portion of the work of data scientists is know how to work around missing values. Let\u0026rsquo;s re-do some of our earlier examples to to get a handle on NAs.\nFirst, what happens if we try and add to a NA?\nNA + 1\nIt will return another NA. Why? Because we don\u0026rsquo;t know what the value of 1 plus an unknown would be, so it is safest to just remain unknown. The same is true with NAs in a vector.\n1 + c(NA, 1, 2)\nWe can get the results for known values, but the unknown will stay unknown. This is true if something uses all elements of a vector, like mean(). Try: mean(c(NA, 5, 10)). Everything turns into an NA, because without knowing all the numbers, we can\u0026rsquo;t be certain what the mean would be.\nNAs do count as an element in a vector though, as we can see if we run length(c(1, 2, 3)) and length(c(NA, 2, 3)). Put simply, NAs exist, we just don\u0026rsquo;t know what they are.\nImagine you are collecting data by asking people questions on a survey. When would you want to write down NA? Is there a difference between NA and someone responding \u0026ldquo;I don\u0026rsquo;t know\u0026rdquo;?\nAn NA is meant to represent missing data. For example, if you handed out a survey, and someone returned it to you without an answer. If someone wrote \u0026lsquo;I don\u0026rsquo;t know\u0026rsquo; that is an answer in itself, and thus not an NA.\n5. Dataframes Recall that dataframes are aggregations of vectors into rows and columns. They must be square, meaning that all the columns must be of equal length, and all rows must have values in every column. There can be NAs though, so watch out! For this section, we\u0026rsquo;re going to be looking at the results of our class survey.\nTo get started, copy the following into the R console and press enter to run it. read.csv is a function that reads tabular (square) data into R and creates a dataframe so we can work with it. We are giving it the argument of the URL for our class data survey to load that data from. We are then asking it to put the results into an object called survey. We will be coming back to this data later on in the problem set.\nYou can learn more about read.csv by opening the help file using ?read.csv.\nsurvey = read.csv(\u0026#34;https://raw.githubusercontent.com/Intro-to-Data-Science-Template/intro_to_data_science_reader/main/content/class_worksheets/4_r_rstudio/data/survey_data.csv\u0026#34;) Exploration Let\u0026rsquo;s start by looking at the survey. You can do this by going over to the Environment tab in the upper right pane in R Studio. Click on the survey object you see there. This will open a viewer for you to look at the data. Can you find yourself?\nWe can also use some functions to get a summary. Start by entering str(survey) into the console. str() stands for Structure, and gives us an overview of dataframe objects. We can see how many obs or observations there are (rows) as well as how many variables there are (columns). It then lists all the variables, what type they are, and a preview of the contents.\nHow many variables are there of each type in the survey dataframe?\nLogical: 6 Integer: 3 Numeric: 0 Character: 14 Another good tool for starting to understand a dataframe is the head() function. head() will display the first handful of rows for you in the console so you can see what they look like. There is also the companion function of tail(), but that is used less often. Try both on our survey data before moving on.\nSubsetting One of the most important skills you will develop in R is how to work with dataframes, and how to subset them, or select only the content from them that you want. The two basic ways to do this is with the dollar sign $ and with square brackets [ ]. The $ lets you ask for specific columns from a dataframe. For example, if I wanted the column of just the average hours of sleep from our class, I could call ask for the hours_sleep column from the survey dataframe by entering survey$hours_sleep. Try that now. You should get back a vector of that single column. The same format will work to call any column by name.\nUsing the $ and the mean(), find the average hours of sleep our class gets per night.\nmean(survey$hours_sleep)\nAnother way to subset dataframes with with square brackets [ ]. Imaging a dataframe is like a map with a grid. You can find any spot on that map by finding the intersection of the grid coordinates. The same is true of a dataframe. For example, if I wanted the value in the third row and fourth column in our survey dataframe (it contains the value 27), I could ask for it by entering survey[*row*, *column*] or survey[3, 4].\nGet the values of each of the following:\nRow 5, column 5 Row 2, column 20 Row 13, column 11 survey[5,5] = r survey[5,5] survey[2,20] = r survey[2,20] survey[13,11] = r survey[13,11] You can also use the square brackets to ask for full columns, like $. Simply put the name of the column (in quotes!) in place of the column number, for example survey[ , \u0026quot;hours_sleep\u0026quot;]. Whenever you want everything, you can just leave a blank space. You can even get whole rows this way, but that isn\u0026rsquo;t used as often; like this survey[1, ].\nA good way to work out how to use square brackets is the phrase \u0026ldquo;such that.\u0026rdquo; For example, if I wanted \u0026ldquo;survey data such that it included rows 1, 2, and 5, and column \u0026lsquo;hours sleep,\u0026rsquo;\u0026rdquo; that would translate to survey[c(1, 2, 5), \u0026quot;hours_sleep\u0026quot;].\nAlways use the names of columns when using square brackets if possible. Columns may move what spot they are in, so calling them by number position can be dangerous. R will return whatever is in that position, regardless of what you want! But it will always find the column with the same name, no matter what spot it is in.\nAdding to Dataframes You can add to dataframes using the same tools to subset from them. Rather than describing where to take data from, you\u0026rsquo;ll now be describing where the new data goes.\nSay we wanted to add a new column to our survey dataframe. First, we would need some new data to add that is of equal length to the number of cases (rows) in the dataframe. We have 15 rows, so we need a vector of data of the same length, so one value will fit into each row of the dataframe. Let\u0026rsquo;s make a new vector of letters of the proper length.\nletters is a pre-built object in R, meaning it is always there in the background; you can see it by typing letters into the console. Let\u0026rsquo;s use our new sub-setting skills to get enough letters to fit our dataframe. We can do this by creating a new object, new_column_vector, and assigning the appropriate number of letters, in our case 15; we can even let R pick the right number using the nrow() function! Try this: new_column_vector \u0026lt;- letters[1:nrow(survey)]. You may have noticed a shortcut I used here. If I want some numbers that are all next to each other, like 1-2-3 or 9-10-11, I can use a colon : to say \u0026ldquo;from this number to this number.\u0026rdquo; So 1:10 is the same thing as c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10); handy!\nNow that we\u0026rsquo;ve got our vector, we can add it to our dataframe! All you have to do is tell R what you want the new column to be called, and what to put in it. It looks like this: survey$COLUMN_NAME \u0026lt;- STUFF_TO_PUT_IN_COLUMN.\nPut our new_column_vector in our survey dataframe, calling the new column alphabet.\nsurvey$alphabet \u0026lt;- new_column_vector\nNow if we inspect out dataframe by clicking on it in the environment pane, we should be able to scroll all the way to the right and see our new column!\n6. Conditionals Another way to subset is by making comparisons. Say we wanted to see the rows in our data only for people whose birthday is in May. If we go look at our survey data in the viewer by clicking on it in the environment pane again, we can see the variable b_month has months in it. Let\u0026rsquo;s test the type of that column using class(survey$b_month)\nNow that we know the type of the b_month column, we can use that to subset the data. Where before we were just taking whole sections of the dataframe, now we are going to be asking for specific parts that match certain conditions, thus this is called conditional sub-setting. We define these conditions using comparison operators.\nComparison For now, we want to get the data only for those rows such that b_month is May. We can do that using the double equal sign comparison operator in R, ==. Comparison operators all compare one thing against another, and tell you if that comparison is TRUE or FALSE. The Equal operator, ==, will test if one thing, or vector of things, is equal to another. For example, try executing the following in the console:\n1 == 1 1 == 2 1 == c(1, 2, 1) Now, let\u0026rsquo;s apply that same idea to our b_month column. Try executing survey$b_month == \u0026quot;May\u0026quot;. This will take our b_month column, and test the condition that the values in b_month are equal to \u0026ldquo;May.\u0026rdquo; Note that capitalization matters! This get\u0026rsquo;s us halfway to our goal of seeing the data only for rows where b_month is May, but it\u0026rsquo;s not quite what we want. We now have a vector of TRUE and FALSE for b_month, now we want to use that to actually subset our data.\nWe are going to ask R for our survey data, such that we only see the rows there b_month is equal to May, including all columns. We can do that using survey[survey$b_month == \u0026quot;May\u0026quot;, ].\nThere are several other common comparison operators, one of the most important being !=, which stands for not equal to. Try running survey[survey$b_month != \u0026quot;May\u0026quot;, ], what does it return? Do you understand why?\nThe most common conditionals include:\n== - Equal to != - Not equal to \u0026gt; - Greater than \u0026gt;= - Greater than or equal to \u0026lt; - Less than \u0026lt;= - Less than or equal to "},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/open_refine/","title":"OpenRefine","tags":[],"description":"","content":" Overview OpenRefine on Windows OpenRefine on Mac Overview OpenRefine is an open source tool used to clean and pre-process messy data. While most people are familiar with data cleaning in their coding tool of choice (R, Python, Julia, etc.), OpenRefine is designed to provide powerful cleaning capabilities with minimal overhead. One of the most helpful capabilities of OpenRefine is the ability to check for possible duplicates and misspellings of text data using it\u0026rsquo;s text facet tools.\nOpenRefine on Windows Open your web browser of choice and navigate to the OpenRefine homepage at https://openrefine.org/. Click on the download button in the left sidebar.\nOn the download page, scroll to the latest version of OpenRefine and select the Windows kit. If you are unsure if you have Java installed on your system, choose the Windows kit with embedded Java instead.\nOnce the download has completed, open the zip and move the contents to a convenient location on your computer.\nOpen the resulting directory, and double click on the openrefine.exe executable.\nThe OpenRefine executable will start a terminal window, and shortly after launch a tab in your default web browser with the OpenRefine interface.\nOpenRefine on Mac First, head to the download page for OpenRefine and choose the latest version for mac.\nOnce the townload has finished, open the downloaded file. Your borwser will most likely show an alert.\nOpen your Applications folder in the finder, and drag OpenRefine into the folder.\nOnce you have dragged the application into the Applications folder, try to open it. If you receive an alert like the following, continue to the next step.\nHold down the Control key and click on OpenRefine. Click open in the menu.\nIt will give you an option to open OpenRefine. Click Open.\nIt will ask if you want OpenRefine to control Safari and access your files. Click OK.\nA safari window will then open, and should look like the following. If that is the case you are all done!\nThanks to the UC Davis DataLab\u0026rsquo;s Install Guide for providing a portion of this guide.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/slides/","title":"Slides","tags":[],"description":"","content":" Lecture Slides 01_1_intro.html (12 MB) 01_2_what_is_data.html (21 MB) 02_2_intro_r.html (8 MB) "},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/class_worksheets/6_git/","title":"git Worksheet","tags":[],"description":"","content":" Overview Problem Sets 1. Make a New Repository 2. Your First Commit 3. Making a Change 4. Adding More Files 5. Breaking Things 6. Time Travel for Beginners Overview git is remarkably useful, but it takes an investment in using it well to gain the full benefits. Today we\u0026rsquo;re going to try and develop some good habits. While they sometimes feel like a chore to adhere to, if you continue on in data science, good git practice will save you some day.\nProblem Sets 1. Make a New Repository All git repositories start with an initialization. For us, that will usually mean starting a new R studio project. It is possible to initialize a git repo in a project that you already have files in, and we will cover that process later in the semester. For now, in the upper right corner of R studio, create a project in a new directory called git_worksheet, and make sure the \u0026ldquo;Create git Repository\u0026rdquo; box is checked when you do.\nOnce the project is created, find the folder in your file browser or finder window, and double click on the \u0026ldquo;git_worksheet.Rproj\u0026rdquo; file to open that R project. In the upper right pane, you should see that there is a tab that says \u0026ldquo;git.\u0026rdquo;\n2. Your First Commit Now that we have a project with a git repository, we can start adding files that we want to keep track of. In general, you want to commit all code files, but not data files. Data files are much larger than what git was made for, and you will quickly run out of storage space on sites like Github if you push them. It is also critically important that you do not commit and files with sensitive information like passwords. Other people will be able to see them, as git is in no way encrypted. It is also very difficult to remove a file from git\u0026rsquo;s memory; it was made to save things!\nNote\nNever commit sensitive files like passwords of API keys.\nCreate a new R script file in your project directory called data_load. Inside this script, in the fist line write a comment (using #) that says \u0026ldquo;This script downloads the data\u0026rdquo;. Next copy the following code into the script.\nsurvey = read.csv(\u0026quot;https://raw.githubusercontent.com/Intro-to-Data-Science-Template/intro_to_data_science_reader/main/content/class_worksheets/4_r_rstudio/data/survey_data.csv\u0026quot;) write.csv(survey, \u0026quot;./survey_data.csv\u0026quot;, row.names = FALSE) This code will read our class survey data, and the write or save the data in our project directory. Execute both the read and write functions, then save that file once you are done and close it.\nLook at the git panel in the upper right pane of R Studio. You should now see (at least) two files there, our survey_code.R script, and the survey_data.csv file we just saved. Both should have yellow question marks next to them. That means git is not currently keeping track of those files.\nWe want to tell git to start tracking our survey_code.R script. To do so, click on the white check box under the \u0026ldquo;Staged\u0026rdquo; column next to survey_code.R. Once you click that, the file is staged, meaning when we make our next commit to the git timeline, that file will be saved.\nLet\u0026rsquo;s make out first commit. In the git pane, click on the \u0026ldquo;Commit\u0026rdquo; button. This will open the commit window. In this window we will see all our files again on the top left, as well as two new areas. In the top right is a box labeled \u0026ldquo;Commit message.\u0026rdquo; This is where you can write a message that will appear on the git timeline describing what you are adding or changing in this commit. For now, type in \u0026ldquo;adding the survey_code script.\u0026rdquo; Press the \u0026ldquo;Commit\u0026rdquo; button once you are done. A progress window will pop up letting you know what is happening. Once it stops changing, you can close it and the commit window.\n3. Making a Change We\u0026rsquo;ve now saved a checkpoint of our survey_code.R script, that we can return to at any point in the future. We can even delete it and bring it back from oblivion! For now, we\u0026rsquo;ll just make some changes to it.\nLet\u0026rsquo;s add some lines of analysis to the script. open it up, and between our read and write scripts, add in the following and save your file:\n# Check the varaibles str(survey) # get the mean hours of sleep mean(survey$hours_sleep) Warning\ngit can only ever see changes to your file after you have saved the file.\nNow that we\u0026rsquo;ve saved out file, it should appear in our git panel again with a blue \u0026ldquo;M\u0026rdquo; next to it, signifying the file has been \u0026ldquo;Modified.\u0026rdquo; Repeat the process of staging it (clicking check box), and committing it (going into the commit menu, adding a message, and pressing commit). We have now added another checkpoint to out git timeline.\n4. Adding More Files Thus far, working with one file seems a lot like saving with extra steps. The true value of git starts to appear once we have multiple files in a project. Create a new R script file called octocat_load.R, and fill it with the following:\n# Code to load in Octocat (github mascot) art octocat = readLines(\u0026quot;https://raw.githubusercontent.com/Intro-to-Data-Science-Template/intro_to_data_science_reader/main/content/class_worksheets/6_git/octocat.txt\u0026quot;) writeLines(octocat, \u0026quot;./octocat.txt\u0026quot;) readLines works like read.csv in that it is a function to load data into R. Instead of loading CSVs though, it loads text files. Execute this code and then commit the octocat_load.R, but not the newly created octocat.txt file.\nCreate another new R script called octocat_print.R. Inside this file, copy the following code into it:\n# to load the local octocat data and print it octocat = readLines(\u0026quot;./octocat.txt\u0026quot;) print(octocat) Save this file and commit it.\nCreate one last script called octocat_count.R. In this script, copy the following:\n# to count the lines in octocat.txt octocat = readLines(\u0026quot;./octocat.txt\u0026quot;) length(octocat) Save this file and commit it. We now have a toy example of a fairly common data science workflow; get the data, inspect the data, and perform analyses on the data.\n5. Breaking Things Now that we have out mini data science workflow, we can start to modify it. Start by opening octocat_load.R. We can replace the readLines function to load the local version of octocat, because we no longer need to grab it from the internet. Replace:\noctocat = readLines(\u0026quot;https://raw.githubusercontent.com/Intro-to-Data-Science-Template/intro_to_data_science_reader/main/content/class_worksheets/6_git/octocat.txt\u0026quot;) With\noctocat = readLines(\u0026quot;./octocat.txt\u0026quot;) Save the file and commit the changes.\nSay we want to quickly modify our octocat art by adding an extra line for a caption. Create a new script called octocat_modify.R and add the following code to it:\n# to add a caption to octocat octocat = readLines(\u0026quot;./octocat.txt\u0026quot;) octocat = c(octocat, \u0026quot;ASCII Art of the Octocat Mascot for Github\u0026quot;) writeChar(octocat, \u0026quot;./octocat.txt\u0026quot;) We use c() here to combine octocat with our caption, and then assign it back to our octocat object. Save the file, execute it, and commit it.\nGreat, now we have out data updated, let\u0026rsquo;s open up our octocat_print.R and run it again to see our beautiful art again.\nUh-oh. It doesn\u0026rsquo;t work anymore. You may have noticed we used the wrong function to save out modified octocat object (we used writeChar rather than writeLines). That\u0026rsquo;s fine, we can load the data in again in our octocat_load.R script\u0026hellip; but we can\u0026rsquo;t because we changed that script to use the local copy which we just broke.\nTime to power up the time machine.\n6. Time Travel for Beginners In the git pane, click on the \u0026ldquo;History\u0026rdquo; button to open up the git timeline. The history window is broken in to to main parts. At the top you have your git timeline, which shows all of your commits in this project. The timeline shows you commit messages, the author of those commits, when the commit happened, and an \u0026ldquo;SHA\u0026rdquo; which you can think of as a unique ID for that commit. On the bottom is the diff or \u0026ldquo;difference\u0026rdquo; window. It will show you what files were changed in that commit, and how they changes. Sections in green were added, while sections in red were removed.\nFind the commit in the timeline where we changed octocat_load.R. Inside the diff window, on the box labeled octocat_load.R, click on the \u0026ldquo;View file @ ########\u0026rdquo; button in the upper right of the box. This will open the file as it was when you committed it. Use this to fix our octocat_load.R script, and save an working copy of octocat.txt again.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/r_packages/","title":"R Packages","tags":[],"description":"","content":" Overview Overview R uses a number of packages to work with data, which are largely community created. This means many of them do not come pre-installed with R. Here is a list of packages we will use this semester. You should be able to paste this into the R console and press enter to install them all at once.\ninstall.packages(\u0026quot;tidyverse\u0026quot;); install.packages(\u0026quot;dplyr\u0026quot;); install.packages(\u0026quot;skimr\u0026quot;); install.packages(\u0026quot;ggplot2\u0026quot;); install.packages(\u0026quot;mosaic\u0026quot;); install.packages(\u0026quot;plotly\u0026quot;); install.packages(\u0026quot;todor\u0026quot;); install.packages(\u0026quot;compareDF\u0026quot;); install.packages(\u0026quot;future\u0026quot;); install.packages(\u0026quot;rvest\u0026quot;); install.packages(\u0026quot;rrefine\u0026quot;); install.packages(\u0026quot;tidycensus\u0026quot;); install.packages(\u0026quot;RSQLite\u0026quot;); install.packages(\u0026quot;sf\u0026quot;); install.packages(\u0026quot;statnet\u0026quot;) To make sure everything was installed, run the following command. It should return TRUE.\nall(c(\u0026quot;tidyverse\u0026quot;, \u0026quot;dplyr\u0026quot;, \u0026quot;skimr\u0026quot;, \u0026quot;ggplot2\u0026quot;, \u0026quot;mosaic\u0026quot;, \u0026quot;plotly\u0026quot;, \u0026quot;todor\u0026quot;, \u0026quot;compareDF\u0026quot;, \u0026quot;future\u0026quot;, \u0026quot;rvest\u0026quot;, \u0026quot;rrefine\u0026quot;, \u0026quot;tidycensus\u0026quot;, \u0026quot;RSQLite\u0026quot;, \u0026quot;sf\u0026quot;, \u0026quot;statnet\u0026quot;) %in% installed.packages()[,\u0026quot;Package\u0026quot;]) "},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/install_guide/wsl/","title":"[WIN ONLY] Windows Subsystem for Linux","tags":[],"description":"","content":" Overview Check your windows version Windows version larger than (or equal to) 19041 Windows version smaller than 19041 Verifying your install Overview Windows now has the ability to install a linux operating system on your machine without the use of an emulator. This gives you a full-featured linux environment that can interact with your normal files.\nCheck your windows version First, please check the build version of Windows that you are using. This can be done by selecting the Windows logo key + r on your keyboard. Once you do that, you should see the windows Run prompt:\nType the command \u0026ldquo;winver\u0026rdquo; (no quotes) into the prompt, as depicted in the image above, and hit enter. You should see a screen similar to this:\nYour build version number is the one that follows the \u0026ldquo;Windows Build\u0026rdquo; text (as highlighted in the above image). Depending on whether your build number is larger or smaller than 19041, please follow the appropriate directions below:\nLarger than (or equal to) 19041 [Smaller than 19041][Windows version larger smaller than 19041] Windows version larger than (or equal to) 19041 In the start menu, search for \u0026ldquo;Powershell\u0026rdquo;, right click and select \u0026ldquo;run as administrator\u0026rdquo;.\nA small blue window should open with a flashing cursor. Please type wsl --install and hit enter:\nThis will take a few minutes to install everything. Once it is finished, please skip to verifying your install.\nIf the above installation did not work- please try to install [using these instructions][Windows version larger smaller than 19041] (even if your version is not smaller than 19041).\nWindows version smaller than 19041 In the start menu, search for \u0026ldquo;Turn Windows features on or off\u0026rdquo; and open that settings window.\nIn the settings window, scroll down to \u0026ldquo;Windows Subsystem for Linux\u0026rdquo;, check the box next to it, and select OK at the bottom of the window.\nYou will not need to restart your computer. Once you have rebooted, open the Windows Store from the start menu.\nIn the Windows Store, search for Ubuntu, and select the version-less one unless you have a reason to pick a specific version.\nOn the Ubuntu page, select Get to install.\nVerifying your install In the start menu, search for and run Ubuntu.\nIf a terminal window opens, you should be good to go!\nThis creates an entirely new operating system on your machine. Thus, things like your git configuration and SSH key for Github will not carry over! You will need to configure git again, and create a new SSH key for this operating system.\nThanks to the UC Davis DataLab\u0026rsquo;s Install Guide for providing a portion of this guide.\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/hidden/radiation_vid/","title":"Content Warning - How history&#39;s worst software error weaponized a radiation machine","tags":[],"description":"","content":"This video contains content that me be distressing to some. It covers topics related to death and cancer, and shows some images of radiation damage on the human body. While gruesome, these topics are important to discuss, given it was a failure in robust coding that caused these tragedies.\nLink to the Perusall Page\n"},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/hidden/","title":"Hidden","tags":[],"description":"","content":""},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/credits/","title":"Credits","tags":[],"description":"","content":"Content Thank you to Dr. Lindsay Poirier and Dr. Ben Baumner for providing their materials as reference as I prepared this course reader.\nThanks to the UC Davis DataLab for providing materials for the install guides.\nBackend Thanks to the Hugo projects for providing the infrastructure for this site. Thank you to the team that created Hugo Learn Theme, the basis of this reader.\nPackages and libraries mermaid - generation of diagram and flowchart from text in a similar manner as markdown font awesome - the iconic font and CSS framework jQuery - The Write Less, Do More, JavaScript Library lunr - Lunr enables you to provide a great search experience without the need for external, server-side, search services\u0026hellip; horsey - Progressive and customizable autocomplete component clipboard.js - copy text to clipboard highlight.js - Javascript syntax highlighter modernizr - A JavaScript toolkit that allows web developers to use new CSS3 and HTML5 features while maintaining a fine level of control over browsers that don\u0026rsquo;t support "},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/","title":"Intro to Data Science","tags":[],"description":"","content":" Intro to Data Science Quick Links Resource Link Description Syllabus Quick access to all important course information. Moodle Grades and quizzes will be available on the course Moodle. Slack Main communication channel for the course. Perusall Perusall page for course readings Spinelli Center The Spinelli Center offers drop-in tutoring hours in Sabin-Reed 301 or on Zoom. Office Hours Sign up for a slot in office hours here. Overview Info Value Who Dr. Jared Joseph What SDS 192-03: Introduction to Data Science When Mondays 1:40-2:55pm; Wednesday/Friday 1:20-2:35pm Where Stoddard G2 Schedule Below is the tentative schedule for the course. While we will try to keep to this schedule, unanticipated situations (and mountain day) may require us to adjust. Each row is a class meeting, with the readings and assignments due on that day listed.\nWeek Date Topic Readings Due 1 9/5/2022 (Mon) No Class 1 9/7/2022 (Wed) Introduction 1 9/9/2022 (Fri) What is Data? Class Syllabus Kitchin, R., \u0026amp; Lauriault, T. P. (2018). Toward Critical Data Studies: Charting and Unpacking Data Assemblages and Their Work. in J. Thatcher, J. Eckert, \u0026amp; A. Shears (Eds.), Thinking Big Data in Geography: New Regimes, New Research (pp. 3-20). University of Nebraska Press. Welcome Survey Data Survey Install Slack and join the class workspace 2 9/12/2022 (Mon) Install Day 2 9/14/2022 (Wed) Intro to R/R Studio (Posit) Irizarry, R. A. (2022). Chapter 2 R basics | Introduction to Data Science. In Introduction to Data Science. All Software Installed 2 9/16/2022 (Fri) Lab 0 \u0026amp; LAB 1 3 9/19/2022 (Mon) Intro to git/GitHub Bryan, J. (2018). Excuse Me, Do You Have a Moment to Talk About Version Control? American Statistician, 72(1), 20-27. 3 9/21/2022 (Wed) Exploratory Data Analyses Irizarry, R. A. (2022). Chapter 12 Robust summaries. In Introduction to Data Science. [PAGES 3-12] Grant, R. (2019). Why visualize? in Data Visualization: Charts, Maps, and Interactive Graphics. Chapman and Hall/CRC. Holtz, Y., \u0026amp; Healy, C. (2018). The issue with pie chart in From data to Viz. Holtz, Y., \u0026amp; Healy, C. (2018). Venn Diagram in From data to Viz. Holtz, Y., \u0026amp; Healy, C. (2018). Line chart in From data to Viz. Holtz, Y., \u0026amp; Healy, C. (2018). Barplot in From data to Viz. Holtz, Y., \u0026amp; Healy, C. (2018). Scatter plot in From data to Viz. Holtz, Y., \u0026amp; Healy, C. (2018). Histogram in From data to Viz. Holtz, Y., \u0026amp; Healy, C. (2018). The Boxplot and its pitfalls in From data to Viz. Lab 0 Lab 1 3 9/23/2022 (Fri) LAB 2 4 9/26/2022 (Mon) Tidy Data/Long-Wide [Section 6.1-6.3] Baumer, B. S., Kaplan, D. T., \u0026amp; Horton, N. J. (2021). Chapter 6 Tidy data. In Modern Data Science with R. CNC Press. 4 9/28/2022 (Wed) Aggregation and Merging Ismay, C., \u0026amp; Kim, A. Y. (2022). Chapter 3 Data Wrangling. In Statistical Inference via Data Science. CNC Press. [PAGES 1701-1731] Ohm, P. (2009). Broken Promises of Privacy: Responding to the Surprising Failure of Anonymization (SSRN Scholarly Paper No. 1450006). Lab 2 4 9/30/2022 (Fri) LAB 3/Quiz 1 Open 5 10/3/2022 (Mon) Advanced Plotting Reynolds, P. (2021). 5 Principles of Visual Perception in Principles of Data Visualization. Irizarry, R. A. (2022). Chapter 8 ggplot2 | Introduction to Data Science. In Introduction to Data Science. Leo, S. (2019, March 27). Mistakes, weve drawn a few. Medium. 5 10/5/2022 (Wed) Interactive Plotting Scroll through Spurious Correlations Explore U.S. Gun Deaths Sievert, C. (2019). 1 Preface. In Interactive web-based data visualization with R, plotly, and shiny. Holtz, Y. (2018). Interactive charts | the R Graph Gallery. Lab 3 5 10/7/2022 (Fri) LAB 4 Quiz 1 6 10/10/2022 (Mon) No Class 6 10/12/2022 (Wed) Data Science Ethics Baumer, B. S., Kaplan, D. T., \u0026amp; Horton, N. J. (2021). Chapter 8 Data science ethics. In Modern Data Science with R. CNC Press. Lab 4 6 10/14/2022 (Fri) Project 1 7 10/17/2022 (Mon) Functions Grolemund, G., \u0026amp; Wickham, H. (2017). 19 Functions. In R for Data Science. O'Reilly. Kyle Hill (Director). (2022, August 31). How history's worst software error weaponized a radiation machine. 7 10/19/2022 (Wed) R Debugging Tools Bryan, J., \u0026amp; Hester, J. (2021). Chapter 11 Debugging R code. In What They Forgot to Teach You About R. 7 10/21/2022 (Fri) LAB 5 8 10/24/2022 (Mon) Iteration Wickham, H., \u0026amp; Grolemund, G. (2017). 21 Iteration. In R for Data Science. O'Reilly. 8 10/26/2022 (Wed) Parallelization Peng, R. D. (2022). 24 Parallel Computation. In R Programming for Data Science. Lab 5 8 10/28/2022 (Fri) LAB 6/Quiz 2 Open Project 1 9 10/31/2022 (Mon) Bash Irizarry, R. A. (2022). Chapter 39 Organizing with Unix. In Introduction to Data Science. 9 11/2/2022 (Wed) Advanced git/GitHub Turing Way Community. (2022). Git Branches. In The Turing Way: A handbook for reproducible, ethical and collaborative research. Zenodo. Turing Way Community. (2022). Merging Branches in Git. In The Turing Way: A handbook for reproducible, ethical and collaborative research. Zenodo. Turing Way Community. (2022). Retrieving and Comparing Versions. In The Turing Way: A handbook for reproducible, ethical and collaborative research. Zenodo. Lab 6 9 11/4/2022 (Fri) LAB 7 Quiz 2 10 11/7/2022 (Mon) Data Cleaning de Jonge, E., \u0026amp; van der Loo, M. (2013). An introduction to data cleaning with R. Rue, J., \u0026amp; Hernandez, R. K. (2019). Using OpenRefine to Clean Your Data. Berkeley Advanced Media Institute. Farivar, C. (2016, August 10). Kansas couple sues IP mapping firm for turning their life into a 'digital hell.' Ars Technica. 10 11/9/2022 (Wed) Recap Lab 7 10 11/11/2022 (Fri) Project 2 11 11/14/2022 (Mon) Web Scraping Irizarry, R. A. (2022). Chapter 24 Web scraping. In Introduction to Data Science. Zimmer, M. (2010). 'But the data is already public': On the ethics of research in Facebook. Ethics and Information Technology, 12(4), 313-325. 11 11/16/2022 (Wed) Remote Servers \u0026amp; APIs TBD 11 11/18/2022 (Fri) LAB 8/Quiz 3 Open 12 11/21/2022 (Mon) SQL TBD Project 2 12 11/23/2022 (Wed) No Class Lab 8 12 11/25/2022 (Fri) No Class Quiz 3 13 11/28/2022 (Mon) Finals Planning Final Project Ideas 13 11/30/2022 (Wed) Text as Data Clark, M. (2018). String Theory. In An Introduction to Text Processing and Analysis with R. Peng, R. D. (2022). 17 Regular Expressions. In R Programming for Data Science. 13 12/2/2022 (Fri) Networks as Data/Quiz 4 Open [Chapters 1-2] Kadushin, C. (2012). Understanding Social Networks: Theories, Concepts, and Findings. Oxford University Press. Berman, G. (2021, November 31). 'Violence Is Contagious': A Conversation with Andrew Papachristos. Harry Frank Guggenheim Foundation. 14 12/5/2022 (Mon) Geospatial Data Baumer, B. S., Kaplan, D. T., \u0026amp; Horton, N. J. (2021). Chapter 17 Working with geospatial data. In Modern Data Science with R. CNC Press. de Montjoye, Y.-A., Hidalgo, C. A., Verleysen, M., \u0026amp; Blondel, V. D. (2013). Unique in the Crowd: The privacy bounds of human mobility. Scientific Reports, 3(1), 1376. Deluca, E., \u0026amp; Nelson, S. (2017). 7. Lying With Maps. In Mapping, Society, and Technology. University of Minnesota Libraries Publishing. 14 12/7/2022 (Wed) Mountain Day Saftey Net/Lessons Learned 14 12/9/2022 (Fri) Finals Work Quiz 4 15 12/12/2022 (Mon) Finals Presentations/aRt Gallery "},{"uri":"https://intro-to-data-science-template.github.io/intro_to_data_science_reader/tags/","title":"Tags","tags":[],"description":"","content":""}]